{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics.pairwise as pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=np.loadtxt('/home/ankita/Desktop/data/wine.txt',dtype='float',delimiter=',',usecols = list(range(1,14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.42300000e+01,   1.71000000e+00,   2.43000000e+00, ...,\n",
       "          1.04000000e+00,   3.92000000e+00,   1.06500000e+03],\n",
       "       [  1.32000000e+01,   1.78000000e+00,   2.14000000e+00, ...,\n",
       "          1.05000000e+00,   3.40000000e+00,   1.05000000e+03],\n",
       "       [  1.31600000e+01,   2.36000000e+00,   2.67000000e+00, ...,\n",
       "          1.03000000e+00,   3.17000000e+00,   1.18500000e+03],\n",
       "       ..., \n",
       "       [  1.32700000e+01,   4.28000000e+00,   2.26000000e+00, ...,\n",
       "          5.90000000e-01,   1.56000000e+00,   8.35000000e+02],\n",
       "       [  1.31700000e+01,   2.59000000e+00,   2.37000000e+00, ...,\n",
       "          6.00000000e-01,   1.62000000e+00,   8.40000000e+02],\n",
       "       [  1.41300000e+01,   4.10000000e+00,   2.74000000e+00, ...,\n",
       "          6.10000000e-01,   1.60000000e+00,   5.60000000e+02]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels=np.loadtxt('/home/ankita/Desktop/data/wine.txt',dtype='float',delimiter=',',usecols = (0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = labels.transpose()\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.42300000e+01,   1.71000000e+00,   2.43000000e+00, ...,\n",
       "          1.04000000e+00,   3.92000000e+00,   1.06500000e+03],\n",
       "       [  1.32000000e+01,   1.78000000e+00,   2.14000000e+00, ...,\n",
       "          1.05000000e+00,   3.40000000e+00,   1.05000000e+03],\n",
       "       [  1.31600000e+01,   2.36000000e+00,   2.67000000e+00, ...,\n",
       "          1.03000000e+00,   3.17000000e+00,   1.18500000e+03],\n",
       "       ..., \n",
       "       [  1.32700000e+01,   4.28000000e+00,   2.26000000e+00, ...,\n",
       "          5.90000000e-01,   1.56000000e+00,   8.35000000e+02],\n",
       "       [  1.31700000e+01,   2.59000000e+00,   2.37000000e+00, ...,\n",
       "          6.00000000e-01,   1.62000000e+00,   8.40000000e+02],\n",
       "       [  1.41300000e+01,   4.10000000e+00,   2.74000000e+00, ...,\n",
       "          6.10000000e-01,   1.60000000e+00,   5.60000000e+02]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = pairwise.rbf_kernel(x,x,gamma=1.0/(2*490))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+000,   3.68818731e-001,   2.05997788e-007, ...,\n",
       "          3.22111554e-024,   3.32822007e-023,   3.22898006e-114],\n",
       "       [  3.68818731e-001,   1.00000000e+000,   7.88033430e-009, ...,\n",
       "          1.91276729e-021,   1.69912115e-020,   3.13077399e-107],\n",
       "       [  2.05997788e-007,   7.88033430e-009,   1.00000000e+000, ...,\n",
       "          3.43444668e-055,   1.20496736e-053,   7.12314865e-174],\n",
       "       ..., \n",
       "       [  3.22111554e-024,   1.91276729e-021,   3.43444668e-055, ...,\n",
       "          1.00000000e+000,   9.71121417e-001,   1.66333393e-034],\n",
       "       [  3.32822007e-023,   1.69912115e-020,   1.20496736e-053, ...,\n",
       "          9.71121417e-001,   1.00000000e+000,   9.78689720e-036],\n",
       "       [  3.22898006e-114,   3.13077399e-107,   7.12314865e-174, ...,\n",
       "          1.66333393e-034,   9.78689720e-036,   1.00000000e+000]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.77748824e-001   5.17984564e-002   4.79817109e-008 ...,\n",
      "    5.45801736e-025   5.50348730e-024   4.03125365e-115]\n",
      " [  5.17984564e-002   1.10968818e-001   1.45029025e-009 ...,\n",
      "    2.56087191e-022   2.21997146e-021   3.08832923e-108]\n",
      " [  4.79817109e-008   1.45029025e-009   3.05224654e-001 ...,\n",
      "    7.62591261e-056   2.61100470e-054   1.16534149e-174]\n",
      " ..., \n",
      " [  5.45801736e-025   2.56087191e-022   7.62591261e-056 ...,\n",
      "    1.61528992e-001   1.53081017e-001   1.97959378e-035]\n",
      " [  5.50348730e-024   2.21997146e-021   2.61100470e-054 ...,\n",
      "    1.53081017e-001   1.53831448e-001   1.13668201e-036]\n",
      " [  4.03125365e-115   3.08832923e-108   1.16534149e-174 ...,\n",
      "    1.97959378e-035   1.13668201e-036   8.76885297e-002]]\n"
     ]
    }
   ],
   "source": [
    "D = np.diag(1.0/np.sqrt(xtrain.sum(axis= 1)))\n",
    "nxtrain = D.dot(xtrain).dot(D)\n",
    "#nxtrain = xtrain/xtrain.sum(axis= 1)\n",
    "print nxtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013745368409439507"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(nxtrain)/178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, Activation, Dropout,Activation\n",
    "from keras.optimizers import Adam, Nadam, RMSprop, Adadelta\n",
    "from keras import regularizers \n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LeakyReLU(alpha):\n",
    "    return Activation('sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-6a8cfc497ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m178\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model = LeakyReLU(alpha=0.1)(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(178,))\n",
    "\n",
    "model = Dense(128)(inputs)\n",
    "#model = LeakyReLU(alpha=0.1)(model)\n",
    "model = sigmoid(alpha = 0.1)(model)\n",
    "model = Dropout(0.8)(model)\n",
    "\n",
    "model = Dense(64, activity_regularizer = regularizers.activity_l1(10e-5),name='embed',activation='sigmoid')(model)\n",
    "\n",
    "model = Dropout(0.8)(model)\n",
    "\n",
    "model = Dense(128)(model)\n",
    "model = LeakyReLU(alpha=0.1)(model)\n",
    "model = Dropout(0.8)(model)\n",
    "\n",
    "model = Dense(178)(model)\n",
    "model = LeakyReLU(alpha=0.1)(model)\n",
    "\n",
    "opt=Adam(lr=0.005, decay=1e-2)\n",
    "#opt=Adadelta()\n",
    "ae = Model(input = inputs, output = model)\n",
    "ae.compile(optimizer=opt, loss='mean_squared_error')\n",
    "ae.fit(nxtrain,nxtrain,nb_epoch= 100, batch_size = 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 178)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.predict(np.expand_dims(nxtrain[0,:],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mm = Model(input= ae.input,output=ae.get_layer('embed').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.predict(np.expand_dims(nxtrain[0,:],0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rec = mm.predict(nxtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u,s,_ = np.linalg.svd(nxtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orig= u[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (178,3) (178,64) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-13c7f922c22e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (178,3) (178,64) "
     ]
    }
   ],
   "source": [
    "np.linalg.norm(orig-rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 2 2 0 0 2 2 0 2 2 2 2 2 2 0 0\n",
      " 2 2 0 0 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 1 0 1 1 0 1 1 0 0 0 1 1 2\n",
      " 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 0 1 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.051664347075296151,\n",
       " 0.4127925661447272,\n",
       " 0.051398038976261912,\n",
       " 0.0054438354437086308,\n",
       " 0.37111371823084754,\n",
       " 0.088370527034240726,\n",
       " 0.09143515133814191,\n",
       " 0.42875686335053037)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "kmeans_bare = KMeans(n_clusters=3,init='random', random_state=None,max_iter=500).fit(x)\n",
    "kmeans_rec = KMeans(n_clusters=3, random_state=0).fit(rec)\n",
    "kmeans_orig = KMeans(n_clusters=3, random_state=0).fit(orig)\n",
    "kmeans_rec.labels_,kmeans_orig.labels_\n",
    "ss_rec = metrics.silhouette_score(nxtrain, kmeans_rec.labels_, metric='euclidean', sample_size=None,random_state=None)\n",
    "ss_orig = metrics.silhouette_score(nxtrain, kmeans_orig.labels_, metric='euclidean', sample_size=None,random_state=None)\n",
    "ss_bare = metrics.silhouette_score(x, kmeans_bare.labels_, metric='euclidean', sample_size=None,random_state=None)\n",
    "\n",
    "ri_rec = metrics.adjusted_rand_score(kmeans_rec.labels_,labels)\n",
    "ri_orig = metrics.adjusted_rand_score(kmeans_orig.labels_,labels)\n",
    "ri_bare = metrics.adjusted_rand_score(kmeans_bare.labels_,labels)\n",
    "\n",
    "nmi_rec = metrics.normalized_mutual_info_score(kmeans_rec.labels_,labels)\n",
    "nmi_orig = metrics.normalized_mutual_info_score(kmeans_orig.labels_,labels)\n",
    "nmi_bare = metrics.normalized_mutual_info_score(kmeans_bare.labels_,labels)\n",
    "print kmeans_bare.labels_\n",
    "ss_rec,ss_orig, ri_rec, ri_orig,ri_bare, nmi_rec,nmi_orig,nmi_bare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def randindex(labels1,labels2):\n",
    "    tp,tn,fp,fn = 0.0,0.0,0.0,0.0\n",
    "    for point1 in range(len(labels1)):\n",
    "        for point2 in range(len(labels1)):\n",
    "            tp += 1 if labels1[point1] == labels1[point2] and labels2[point1] == labels2[point2] else 0\n",
    "            tn += 1 if labels1[point1] != labels1[point2] and labels2[point1] != labels2[point2] else 0\n",
    "            fp += 1 if labels1[point1] != labels1[point2] and labels2[point1] == labels2[point2] else 0\n",
    "            fn += 1 if labels1[point1] == labels1[point2] and labels2[point1] != labels2[point2] else 0\n",
    "    return (tp+tn) /(tp+tn+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5566847620249968, 0.3646635525817447, 0.720237343769726)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randindex(kmeans_rec.labels_,labels),randindex(kmeans_orig.labels_,labels),randindex(kmeans_bare.labels_,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-8bd1826c926a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mblobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_blobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.clustering import SpectralClustering\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn import metrics\n",
    "\n",
    "numpy.linalg.eigh()\n",
    "np.random.seed(0)\n",
    "blobs = datasets.make_blobs(n_samples=1500, random_state=8)\n",
    "X, y = blobs\n",
    "X = StandardScaler().fit_transform(X)\n",
    "spectral = cluster.SpectralClustering(n_clusters=3,eigen_solver='arpack')\n",
    "#spectral = cluster.SpectralClustering(n_clusters=3,eigen_solver='arpack',affinity = 'nearest_neighbors')\n",
    "spectral.fit(X)\n",
    "if hasattr(spectral, 'labels_'):\n",
    "        y_pred = spectral.labels_.astype(np.int)\n",
    "else:\n",
    "        y_pred = spectral.predict(X)\n",
    "\n",
    "ss = metrics.silhouette_score(X, y_pred, metric='euclidean', sample_size=None,random_state=None)\n",
    "\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_collected_trainable_weights',\n",
       " '_fit_loop',\n",
       " '_function_kwargs',\n",
       " '_get_node_attribute_at_index',\n",
       " '_make_predict_function',\n",
       " '_make_test_function',\n",
       " '_make_train_function',\n",
       " '_output_mask_cache',\n",
       " '_output_shape_cache',\n",
       " '_output_tensor_cache',\n",
       " '_predict_loop',\n",
       " '_standardize_user_data',\n",
       " '_test_loop',\n",
       " '_updated_config',\n",
       " 'add_inbound_node',\n",
       " 'add_loss',\n",
       " 'add_update',\n",
       " 'add_weight',\n",
       " 'assert_input_compatibility',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compile',\n",
       " 'compute_mask',\n",
       " 'constraints',\n",
       " 'container_nodes',\n",
       " 'count_params',\n",
       " 'create_input_layer',\n",
       " 'evaluate',\n",
       " 'evaluate_generator',\n",
       " 'fit',\n",
       " 'fit_generator',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_layer',\n",
       " 'get_losses_for',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_output_shape_for',\n",
       " 'get_updates_for',\n",
       " 'get_weights',\n",
       " 'history',\n",
       " 'inbound_nodes',\n",
       " 'input',\n",
       " 'input_layers',\n",
       " 'input_layers_node_indices',\n",
       " 'input_layers_tensor_indices',\n",
       " 'input_mask',\n",
       " 'input_names',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'inputs',\n",
       " 'internal_input_shapes',\n",
       " 'internal_output_shapes',\n",
       " 'layers',\n",
       " 'layers_by_depth',\n",
       " 'load_weights',\n",
       " 'load_weights_from_hdf5_group',\n",
       " 'load_weights_from_hdf5_group_by_name',\n",
       " 'loss',\n",
       " 'loss_functions',\n",
       " 'loss_weights',\n",
       " 'losses',\n",
       " 'metrics',\n",
       " 'metrics_names',\n",
       " 'metrics_tensors',\n",
       " 'name',\n",
       " 'nodes_by_depth',\n",
       " 'non_trainable_weights',\n",
       " 'optimizer',\n",
       " 'outbound_nodes',\n",
       " 'output',\n",
       " 'output_layers',\n",
       " 'output_layers_node_indices',\n",
       " 'output_layers_tensor_indices',\n",
       " 'output_mask',\n",
       " 'output_names',\n",
       " 'output_shape',\n",
       " 'outputs',\n",
       " 'predict',\n",
       " 'predict_function',\n",
       " 'predict_generator',\n",
       " 'predict_on_batch',\n",
       " 'regularizers',\n",
       " 'reset_states',\n",
       " 'run_internal_graph',\n",
       " 'sample_weight_mode',\n",
       " 'sample_weight_modes',\n",
       " 'sample_weights',\n",
       " 'save',\n",
       " 'save_weights',\n",
       " 'save_weights_to_hdf5_group',\n",
       " 'set_weights',\n",
       " 'state_updates',\n",
       " 'stateful',\n",
       " 'stop_training',\n",
       " 'summary',\n",
       " 'supports_masking',\n",
       " 'targets',\n",
       " 'test_function',\n",
       " 'test_on_batch',\n",
       " 'to_json',\n",
       " 'to_yaml',\n",
       " 'total_loss',\n",
       " 'train_function',\n",
       " 'train_on_batch',\n",
       " 'trainable',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'uses_learning_phase',\n",
       " 'validation_data',\n",
       " 'weights']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1468:0' shape=(?, 64) dtype=float32>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.get_layer('embed').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
